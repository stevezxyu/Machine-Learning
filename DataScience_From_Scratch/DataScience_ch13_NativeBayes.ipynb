{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "貝氏定理 (Bayes Theory)\n",
    "'''\n",
    "from collections import defaultdict, Counter\n",
    "import math\n",
    "\n",
    "# 拆分單字\n",
    "def tokenize(message):\n",
    "    message = message.lower()                       # transmit lower\n",
    "    all_words = re.findall(\"[a-z0-9]+\", message)    # pick up words\n",
    "    return set(all_words)                           # remove repeat parts\n",
    "\n",
    "def count_words(training_set):\n",
    "    '''\n",
    "    訓練組資料 training_set 包含了許多兩兩成對的 (message, is_spam)\n",
    "    '''\n",
    "    counts = defaultdict(lambda: [0, 0])\n",
    "    for message, is_spam in training_set:\n",
    "        for word in tokenize(message):\n",
    "            counts[word][o if is_spam else 1] += 1\n",
    "    return counts\n",
    "\n",
    "# 計數值轉換成機率的估計值\n",
    "def word_probabilities(counts, total_spams, total_non_spams, k=0.5):\n",
    "    '''\n",
    "    把 word_counts 轉換成 tuple\n",
    "    w, p(w | spam) and p(w | ~spam)\n",
    "    '''\n",
    "    return [(w,(spam + k) / (total_spams + 2 * k),\n",
    "            (non_spam + k) / (total_non_spams + 2 * k))\n",
    "           for w, (spam, non_spam) in counts.iteritems()]\n",
    "    \n",
    "# 單詞的相關機率值\n",
    "def spam_probabilities(word_probs, message):\n",
    "    message_words = tokenize(message)\n",
    "    log_prob_if_spam = log_prob_if_not_spam = 0.0\n",
    "    # 詞彙表中的每個單詞進行迭代操作\n",
    "    for word, prob_if_spam, prob_if_not_spam in word_probs:\n",
    "        # 如果郵件中有出現相應單詞\n",
    "        # 把該單詞有出現的相應機率取對數之後，再累加進去\n",
    "        if word in message_words:\n",
    "            log_prob_if_spam += math.log(prob_if_spam)\n",
    "            log_prob_if_not_spam += math.log(prob_if_not_spam)\n",
    "            \n",
    "        # 如果郵件中沒出現相應單詞\n",
    "        # 就該把單詞沒出現的相應機率取對數之後，再累加進去\n",
    "        # 單詞沒出現的相應機率，就等於 (1-單詞有出現的機率)\n",
    "        else:\n",
    "            log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
    "            log_prob_if_not_spam += math.log(1.0 - prob_if_not_spam)\n",
    "            \n",
    "    prob_if_spam = math.exp(log_prob_if_spam)\n",
    "    prob_if_not_spam = math.exp(log_prob_if_not_spam)\n",
    "    return prob_if_spam / (prob_if_spam + prob_if_not_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 整合到貝氏分類器之中\n",
    "class NativeBayesClassifier:\n",
    "    \n",
    "    def __init__(self, k=0.5):\n",
    "        self.k = k\n",
    "        self.word_probs = []\n",
    "        \n",
    "    def train(self, training_set):\n",
    "        # 計算垃圾郵件與非垃圾郵件的數量\n",
    "        num_spams = len([is_spam\n",
    "                        for message, is_spam in training_set\n",
    "                        if is_spam])\n",
    "        num_non_spams = len(training_set) - num_spams\n",
    "        \n",
    "        # 運用訓練組數據，執行所設計的相關運算\n",
    "        word_counts = count_words(training_set)\n",
    "        self.word_probs = word_probabilities(word_counts,\n",
    "                                            num_spams,\n",
    "                                            num_non_spams,\n",
    "                                            self.k)\n",
    "\n",
    "    def classify(self, message):\n",
    "        return spam_probability(self.word_probs, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'machine_learning'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-f1f92d20a795>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m '''\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCounter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmachine_learning\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msplit_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# 將路徑修改為實際上你存放的位置\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'machine_learning'"
     ]
    }
   ],
   "source": [
    "'''\n",
    "測試模型\n",
    "'''\n",
    "from collections import Counter, defaultdict\n",
    "from machine_learning import split_data\n",
    "import math, random, re, glob\n",
    "# 將路徑修改為實際上你存放的位置\n",
    "path = r\"C:\\Downloads\\*\\*\"\n",
    "\n",
    "def get_subject_data(path):\n",
    "\n",
    "    data = []\n",
    "\n",
    "    # glob.glob 會送回每一個符合通配 (wildcarded) 路徑的相應檔案名稱\n",
    "    for fn in glob.glob(path):\n",
    "        is_spam = \"ham\" not in fn\n",
    "\n",
    "        with open(fn,'r',encoding='ISO-8859-1') as file:\n",
    "            for line in file:\n",
    "                if line.startswitch(\"Subject:\"):\n",
    "                    # 移除開頭的 \"Subject: \" 字樣，保留其餘的部分\n",
    "                    subject = re.sub(r\"^Subject: \", \"\", line).strip()\n",
    "                    data.append((subject, is_spam))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_spam_given_word(word_prob):\n",
    "    word, prob_if_spam, prob_if_not_spam = word_prob\n",
    "    return prob_if_spam / (prob_if_spam + prob_if_not_spam)\n",
    "\n",
    "def train_and_test_model(path):\n",
    "    data = get_subject_data(path)\n",
    "    random.seed(0)      # just so you get the same answers as me\n",
    "    train_data, test_data = split_data(data, 0.75)\n",
    "\n",
    "    classifier = NaiveBayesClassifier()\n",
    "    classifier.train(train_data)\n",
    "\n",
    "    # 元組: (主旨，是否確實為垃圾郵件，預測為垃圾郵件的機率)\n",
    "    classified = [(subject, is_spam, classifier.classify(subject))\n",
    "                 for subject, is_spam in test_data]\n",
    "\n",
    "    # 假設 spam_probability > 0.5 對應的是預測為垃圾郵件\n",
    "    # 計算 (是否確實為垃圾郵件，是否預測為垃圾郵件) 組合的數量\n",
    "    counts = Counter((is_spam, spam_probability > 0.5)\n",
    "                    for _, is_spam, spam_probability in classified)\n",
    "    print(counts)\n",
    "\n",
    "    # 根據垃圾郵件機率 (spam_probability) 從最小到最大進行排序\n",
    "    classified.sort(key=lambda row: row[2])\n",
    "\n",
    "    # 在非垃圾郵件中，被預測為垃圾郵件的最高機率者\n",
    "    spammiest_hams = filter(lambda row: not row[1], classified)[-5:]\n",
    "\n",
    "    # 在垃圾郵件中，被預測為垃圾郵件的最低機率者\n",
    "    hammiest_spams = filter(lambda row: row[1], classified)[:5]\n",
    "\n",
    "    print(\"spammiest_hams\", spammiest_hams)\n",
    "    print(\"hammiest_spams\", hammiest_spams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-a298136af061>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mprob_spam\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprob_if_spam\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mprob_if_not_spam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mword_probs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp_spam_given_word\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mspammiest_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "def p_spam_given_word(word_prob):\n",
    "    '''\n",
    "    運用貝氏定理計算郵件包含某單詞情況下，該郵件為垃圾郵件的機率\n",
    "    '''\n",
    "    # word_prob 是由 word_probabilities 所生成的其中之一個元組\n",
    "    word, prob_if_spam, prob_if_not_spam = word_prob\n",
    "    return prob_spam / (prob_if_spam + prob_if_not_spam)\n",
    "    \n",
    "words = sorted(classifier.word_probs, key=p_spam_given_word)\n",
    "\n",
    "spammiest_words = words[-5:]\n",
    "hammiest_words = words[:5]\n",
    "\n",
    "print(\"spammiest_words\", spammiest_words)\n",
    "print(\"hammiest_words\", hammiest_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 單辭轉換成同類詞\n",
    "def drop_final_s(word):\n",
    "    return re.sub(\"s$\", \"\", word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
